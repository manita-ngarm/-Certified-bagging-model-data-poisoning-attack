{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGIPzpTvCuxp"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "#from keras.backend.tensorflow_backend import set_session\n",
        "import numpy as np\n",
        "import os\n",
        "#import dataaug\n",
        "#from keras.backend import set_session\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHRP8MTmDLri",
        "outputId": "ca4592bc-cd59-4959-fa35-30b906face48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "batch_size = 16\n",
        "num_classes = 10\n",
        "epochs = 200\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVQBJaG5DOYy"
      },
      "outputs": [],
      "source": [
        "#count label\n",
        "def count_labels(label):\n",
        "    count_train_labels = np.zeros([1, num_classes], dtype=int)\n",
        "    for i in range(label.shape[0]):\n",
        "        a = np.argmax(label[i])\n",
        "        count_train_labels[np.arange(0, 1), a] += 1\n",
        "    return (count_train_labels, np.sum(count_train_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcOtvFceDQwg",
        "outputId": "a5bc77ff-85a4-4f48-b412-b7e353eeae2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "#poisoning label\n",
        "def poisoning_labels(label, size):\n",
        "    #print(count_labels(label))\n",
        "    for i in range(size):\n",
        "        a = np.argmax(label[i])\n",
        "        label[i][a] = 0\n",
        "        if a == 0:\n",
        "            label[i][1] = 1\n",
        "        else: label[i][0] = 1\n",
        "    #print((count_labels(label)))\n",
        "    return(label)       \n",
        "poisoning_labels(y_train,50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulzz2a4qDSGb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "def DataGeneratorFunMNIST():\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=10,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.0,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.0,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=False,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=\"channels_last\",\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "    return datagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcocFBP-DYIR"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              #Adadelta(),\n",
        "              #SGD(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "## here we use the same initialization for all models, and you can also use different initialization for different models\n",
        "weights_initialize = model.get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdHVNtW7DbHb",
        "outputId": "a9c29d2e-fab9-401d-8403-a85ca4f095a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([[5965, 6739, 5954, 6124, 5838, 5417, 5913, 6261, 5847, 5942]]), 60000)\n",
            "(array([[8311, 6730, 5659, 5836, 5517, 5147, 5612, 5936, 5590, 5662]]), 60000)\n"
          ]
        }
      ],
      "source": [
        "### Set the parameters\n",
        "k_value = 30\n",
        "end = 100\n",
        "poisoning_size = 3000\n",
        "\n",
        "''' \n",
        "track the label frequency for each testing input, and the last dimension is used to save the true label, \n",
        "which is further used to compute the certified radius\n",
        "'''\n",
        "aggregate_result = np.zeros([x_test.shape[0], num_classes + 1], dtype=int)\n",
        "\n",
        "#check poisoning label\n",
        "print(count_labels(y_train))\n",
        "y_train = poisoning_labels(y_train,poisoning_size)\n",
        "print(count_labels(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3CFEC38Dtoq",
        "outputId": "67f37d73-9eb3-48f2-ad90-54063732b7f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 2.867896795272827\n",
            "Test accuracy: 0.6710000038146973\n",
            "[7 2 1 ... 4 5 0]\n",
            "Test loss: 1.304474949836731\n",
            "Test accuracy: 0.7283999919891357\n",
            "[7 2 1 ... 9 5 6]\n",
            "Test loss: 1.9272674322128296\n",
            "Test accuracy: 0.6554999947547913\n",
            "[7 2 1 ... 4 8 6]\n",
            "Test loss: 1.0956181287765503\n",
            "Test accuracy: 0.753600001335144\n",
            "[7 2 1 ... 4 0 6]\n",
            "Test loss: 3.391611337661743\n",
            "Test accuracy: 0.6262000203132629\n",
            "[8 2 8 ... 4 5 6]\n",
            "Test loss: 1.6736515760421753\n",
            "Test accuracy: 0.6496999859809875\n",
            "[7 0 1 ... 4 8 6]\n",
            "Test loss: 1.3865855932235718\n",
            "Test accuracy: 0.6891000270843506\n",
            "[7 2 1 ... 4 4 6]\n",
            "Test loss: 1.849130630493164\n",
            "Test accuracy: 0.6359999775886536\n",
            "[7 2 1 ... 4 3 6]\n",
            "Test loss: 3.51739501953125\n",
            "Test accuracy: 0.6388999819755554\n",
            "[7 2 1 ... 4 5 2]\n",
            "Test loss: 3.4684839248657227\n",
            "Test accuracy: 0.5860999822616577\n",
            "[7 2 7 ... 4 5 2]\n",
            "Test loss: 1.714108943939209\n",
            "Test accuracy: 0.6873000264167786\n",
            "[7 2 1 ... 9 5 6]\n",
            "Test loss: 1.7913686037063599\n",
            "Test accuracy: 0.6653000116348267\n",
            "[7 2 1 ... 9 1 6]\n",
            "Test loss: 1.2655029296875\n",
            "Test accuracy: 0.7272999882698059\n",
            "[7 2 1 ... 9 5 6]\n",
            "Test loss: 2.9362025260925293\n",
            "Test accuracy: 0.6262000203132629\n",
            "[7 2 1 ... 4 0 6]\n",
            "Test loss: 2.7103493213653564\n",
            "Test accuracy: 0.6959999799728394\n",
            "[7 3 1 ... 4 5 6]\n",
            "Test loss: 1.8531558513641357\n",
            "Test accuracy: 0.6791999936103821\n",
            "[7 2 1 ... 8 8 6]\n",
            "Test loss: 3.4295895099639893\n",
            "Test accuracy: 0.5722000002861023\n",
            "[7 6 7 ... 4 0 6]\n",
            "Test loss: 4.063198566436768\n",
            "Test accuracy: 0.4936000108718872\n",
            "[7 2 1 ... 8 8 0]\n",
            "Test loss: 3.13746976852417\n",
            "Test accuracy: 0.6486999988555908\n",
            "[7 2 1 ... 4 9 0]\n",
            "Test loss: 2.058659076690674\n",
            "Test accuracy: 0.6273999810218811\n",
            "[9 2 1 ... 4 5 6]\n",
            "Test loss: 2.1293745040893555\n",
            "Test accuracy: 0.722599983215332\n",
            "[7 2 1 ... 9 8 6]\n",
            "Test loss: 3.1024467945098877\n",
            "Test accuracy: 0.5942000150680542\n",
            "[7 2 0 ... 4 5 6]\n",
            "Test loss: 3.260960578918457\n",
            "Test accuracy: 0.5644999742507935\n",
            "[7 2 1 ... 4 0 0]\n",
            "Test loss: 2.0923354625701904\n",
            "Test accuracy: 0.6279000043869019\n",
            "[7 2 1 ... 9 5 0]\n",
            "Test loss: 2.1566004753112793\n",
            "Test accuracy: 0.6908000111579895\n",
            "[7 2 1 ... 4 8 6]\n",
            "Test loss: 1.2191429138183594\n",
            "Test accuracy: 0.7433000206947327\n",
            "[7 2 1 ... 4 5 6]\n",
            "Test loss: 1.9468566179275513\n",
            "Test accuracy: 0.5859000086784363\n",
            "[7 2 0 ... 4 5 6]\n",
            "Test loss: 2.189134359359741\n",
            "Test accuracy: 0.7281000018119812\n",
            "[7 2 1 ... 9 8 6]\n",
            "Test loss: 3.3900063037872314\n",
            "Test accuracy: 0.5960000157356262\n",
            "[7 2 1 ... 4 0 6]\n",
            "Test loss: 1.6970995664596558\n",
            "Test accuracy: 0.6927000284194946\n",
            "[7 2 1 ... 4 5 6]\n",
            "Test loss: 1.6517373323440552\n",
            "Test accuracy: 0.7117999792098999\n",
            "[7 2 1 ... 4 4 6]\n",
            "Test loss: 3.186829090118408\n",
            "Test accuracy: 0.5982000231742859\n",
            "[7 2 1 ... 8 1 6]\n",
            "Test loss: 2.5539278984069824\n",
            "Test accuracy: 0.6057999730110168\n",
            "[7 2 0 ... 4 5 0]\n",
            "Test loss: 2.5527307987213135\n",
            "Test accuracy: 0.6150000095367432\n",
            "[7 2 1 ... 9 5 6]\n",
            "Test loss: 2.7366960048675537\n",
            "Test accuracy: 0.6783000230789185\n",
            "[7 2 1 ... 4 6 6]\n",
            "Test loss: 2.4021124839782715\n",
            "Test accuracy: 0.666700005531311\n",
            "[7 2 1 ... 4 5 6]\n",
            "Test loss: 4.2259368896484375\n",
            "Test accuracy: 0.527400016784668\n",
            "[7 6 4 ... 4 8 6]\n",
            "Test loss: 1.3328897953033447\n",
            "Test accuracy: 0.7093999981880188\n",
            "[7 3 1 ... 4 5 6]\n",
            "Test loss: 4.955506801605225\n",
            "Test accuracy: 0.5454999804496765\n",
            "[8 8 1 ... 9 0 6]\n",
            "Test loss: 2.3738150596618652\n",
            "Test accuracy: 0.6676999926567078\n",
            "[7 2 6 ... 4 5 6]\n",
            "Test loss: 2.006082534790039\n",
            "Test accuracy: 0.6891000270843506\n",
            "[7 0 1 ... 4 8 6]\n",
            "Test loss: 1.8634095191955566\n",
            "Test accuracy: 0.5812000036239624\n",
            "[7 0 1 ... 4 0 6]\n",
            "Test loss: 2.082897901535034\n",
            "Test accuracy: 0.6802999973297119\n",
            "[7 2 1 ... 4 5 6]\n",
            "Test loss: 1.4545294046401978\n",
            "Test accuracy: 0.6818000078201294\n",
            "[7 2 1 ... 4 5 6]\n",
            "Test loss: 3.030139446258545\n",
            "Test accuracy: 0.5963000059127808\n",
            "[7 1 1 ... 0 8 6]\n",
            "Test loss: 1.430863618850708\n",
            "Test accuracy: 0.6484000086784363\n",
            "[7 2 1 ... 1 8 6]\n",
            "Test loss: 2.7039806842803955\n",
            "Test accuracy: 0.6031000018119812\n",
            "[7 2 1 ... 9 9 0]\n",
            "Test loss: 3.841583490371704\n",
            "Test accuracy: 0.5103999972343445\n",
            "[7 2 1 ... 9 5 0]\n",
            "Test loss: 2.123847723007202\n",
            "Test accuracy: 0.6470000147819519\n",
            "[2 2 1 ... 4 5 6]\n",
            "Test loss: 1.388085961341858\n",
            "Test accuracy: 0.7384999990463257\n",
            "[7 3 1 ... 4 5 6]\n",
            "Test loss: 4.10225772857666\n",
            "Test accuracy: 0.5016999840736389\n",
            "[7 3 1 ... 4 5 0]\n",
            "Test loss: 2.5709853172302246\n",
            "Test accuracy: 0.6251999735832214\n",
            "[7 2 1 ... 4 5 6]\n",
            "Test loss: 1.6486011743545532\n",
            "Test accuracy: 0.6513000130653381\n",
            "[7 2 1 ... 9 5 6]\n",
            "Test loss: 2.002432107925415\n",
            "Test accuracy: 0.6572999954223633\n",
            "[7 2 1 ... 4 0 6]\n",
            "Test loss: 2.2849485874176025\n",
            "Test accuracy: 0.6025000214576721\n",
            "[7 1 1 ... 1 5 6]\n",
            "Test loss: 1.708232045173645\n",
            "Test accuracy: 0.6589000225067139\n",
            "[7 2 1 ... 9 8 6]\n",
            "Test loss: 2.2877016067504883\n",
            "Test accuracy: 0.6553000211715698\n",
            "[7 6 1 ... 9 5 6]\n",
            "Test loss: 1.7323722839355469\n",
            "Test accuracy: 0.6754999756813049\n",
            "[7 2 1 ... 4 5 5]\n",
            "Test loss: 1.5390238761901855\n",
            "Test accuracy: 0.6786999702453613\n",
            "[7 2 1 ... 4 8 9]\n",
            "Test loss: 2.7140445709228516\n",
            "Test accuracy: 0.6037999987602234\n",
            "[7 2 1 ... 7 0 6]\n",
            "Test loss: 1.3196930885314941\n",
            "Test accuracy: 0.7304999828338623\n",
            "[7 2 1 ... 4 8 6]\n",
            "Test loss: 2.1150736808776855\n",
            "Test accuracy: 0.6836000084877014\n",
            "[7 2 1 ... 4 5 6]\n",
            "Test loss: 3.296635627746582\n",
            "Test accuracy: 0.5834000110626221\n",
            "[7 2 1 ... 4 5 6]\n",
            "Test loss: 2.240427017211914\n",
            "Test accuracy: 0.6908000111579895\n",
            "[7 2 1 ... 4 9 6]\n",
            "Test loss: 1.9638949632644653\n",
            "Test accuracy: 0.6930999755859375\n",
            "[7 2 1 ... 4 8 6]\n",
            "Test loss: 3.2383925914764404\n",
            "Test accuracy: 0.5954999923706055\n",
            "[7 8 1 ... 4 8 6]\n",
            "Test loss: 4.070951461791992\n",
            "Test accuracy: 0.6037999987602234\n",
            "[7 3 1 ... 4 8 6]\n",
            "Test loss: 1.7146550416946411\n",
            "Test accuracy: 0.6775000095367432\n",
            "[7 2 1 ... 4 5 0]\n",
            "Test loss: 1.7534984350204468\n",
            "Test accuracy: 0.703000009059906\n",
            "[7 2 1 ... 4 9 6]\n",
            "Test loss: 1.7875086069107056\n",
            "Test accuracy: 0.6424999833106995\n",
            "[7 2 1 ... 8 5 6]\n",
            "Test loss: 3.0830276012420654\n",
            "Test accuracy: 0.5374000072479248\n",
            "[7 3 1 ... 9 5 6]\n",
            "Test loss: 1.7200040817260742\n",
            "Test accuracy: 0.6947000026702881\n",
            "[7 2 1 ... 9 5 6]\n",
            "Test loss: 3.132129669189453\n",
            "Test accuracy: 0.5807999968528748\n",
            "[7 2 1 ... 9 5 6]\n",
            "Test loss: 3.585411787033081\n",
            "Test accuracy: 0.5627999901771545\n",
            "[7 2 1 ... 0 0 0]\n",
            "Test loss: 3.0906267166137695\n",
            "Test accuracy: 0.5665000081062317\n",
            "[7 2 1 ... 1 8 4]\n",
            "Test loss: 2.7925939559936523\n",
            "Test accuracy: 0.6402000188827515\n",
            "[7 8 1 ... 9 5 6]\n",
            "Test loss: 1.2073053121566772\n",
            "Test accuracy: 0.7724999785423279\n",
            "[7 2 1 ... 9 5 6]\n",
            "Test loss: 2.335648536682129\n",
            "Test accuracy: 0.6708999872207642\n",
            "[2 2 1 ... 4 0 6]\n",
            "Test loss: 2.6799535751342773\n",
            "Test accuracy: 0.608299970626831\n",
            "[7 0 1 ... 4 8 0]\n",
            "Test loss: 2.1840147972106934\n",
            "Test accuracy: 0.641700029373169\n",
            "[7 2 1 ... 4 4 4]\n",
            "Test loss: 1.1923484802246094\n",
            "Test accuracy: 0.7293000221252441\n",
            "[7 2 1 ... 9 5 6]\n",
            "Test loss: 1.3383586406707764\n",
            "Test accuracy: 0.7253999710083008\n",
            "[7 2 1 ... 4 8 6]\n",
            "Test loss: 1.5765475034713745\n",
            "Test accuracy: 0.660099983215332\n",
            "[7 2 0 ... 6 5 6]\n",
            "Test loss: 1.41584312915802\n",
            "Test accuracy: 0.7473999857902527\n",
            "[7 2 1 ... 9 5 6]\n",
            "Test loss: 2.568251848220825\n",
            "Test accuracy: 0.6801999807357788\n",
            "[7 2 1 ... 9 8 6]\n",
            "Test loss: 1.2053028345108032\n",
            "Test accuracy: 0.7300000190734863\n",
            "[7 2 1 ... 9 5 6]\n",
            "Test loss: 2.9212355613708496\n",
            "Test accuracy: 0.5748999714851379\n",
            "[7 2 1 ... 9 8 8]\n",
            "Test loss: 2.807299852371216\n",
            "Test accuracy: 0.6650000214576721\n",
            "[7 2 1 ... 4 0 6]\n",
            "Test loss: 2.3868768215179443\n",
            "Test accuracy: 0.6317999958992004\n",
            "[9 2 1 ... 9 8 6]\n",
            "Test loss: 3.2392194271087646\n",
            "Test accuracy: 0.6011999845504761\n",
            "[3 2 1 ... 9 8 0]\n",
            "Test loss: 2.4079184532165527\n",
            "Test accuracy: 0.5910999774932861\n",
            "[0 2 1 ... 9 5 6]\n",
            "Test loss: 1.8785403966903687\n",
            "Test accuracy: 0.6912000179290771\n",
            "[7 2 1 ... 4 8 6]\n",
            "Test loss: 2.841754198074341\n",
            "Test accuracy: 0.5773000121116638\n",
            "[7 8 1 ... 8 8 6]\n",
            "Test loss: 1.5591760873794556\n",
            "Test accuracy: 0.7285000085830688\n",
            "[7 2 1 ... 0 8 6]\n",
            "Test loss: 2.227739095687866\n",
            "Test accuracy: 0.6812999844551086\n",
            "[7 3 1 ... 4 8 6]\n",
            "Test loss: 3.165438175201416\n",
            "Test accuracy: 0.6032000184059143\n",
            "[7 2 6 ... 4 5 6]\n",
            "Test loss: 1.0481607913970947\n",
            "Test accuracy: 0.7809000015258789\n",
            "[7 2 1 ... 4 5 6]\n",
            "Test loss: 2.8392858505249023\n",
            "Test accuracy: 0.6211000084877014\n",
            "[7 2 1 ... 4 5 4]\n",
            "Test loss: 2.046661615371704\n",
            "Test accuracy: 0.6079999804496765\n",
            "[7 2 1 ... 1 5 0]\n",
            "Test loss: 1.2398122549057007\n",
            "Test accuracy: 0.7491999864578247\n",
            "[7 3 1 ... 4 5 4]\n",
            "Complete\n"
          ]
        }
      ],
      "source": [
        "## data augmentation function\n",
        "\n",
        "datagen = DataGeneratorFunMNIST()\n",
        "\n",
        "\n",
        "for repeat_time in range(end):\n",
        "    # sampling with replacement.\n",
        "    sample_index = np.random.choice(x_train.shape[0], k_value, replace=True)\n",
        "\n",
        "    x_train_sample = x_train[sample_index, :, :, :]\n",
        "    y_train_sample = y_train[sample_index, :]\n",
        "\n",
        "    # train the model\n",
        "    model.fit(datagen.flow(x_train_sample, y_train_sample, batch_size=batch_size),\n",
        "                        epochs=epochs, verbose=0, workers=4)\n",
        "\n",
        "    # evaluate the base model and you can also comment it without influencing the results.\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test loss:', score[0])\n",
        "    print('Test accuracy:', score[1])\n",
        "\n",
        "    prediction_label = np.argmax(model.predict(x_test), axis=1)\n",
        "    print(prediction_label)\n",
        "    aggregate_result[np.arange(0, x_test.shape[0]), prediction_label] += 1\n",
        "    # reinitialize the model, note that you can also use different parameters to initialize the model\n",
        "    model.set_weights(weights_initialize)\n",
        "aggregate_result[np.arange(0, x_test.shape[0]), -1] = np.argmax(y_test, axis=1)\n",
        "\n",
        "print('Complete')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9flnfGGEMty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bdf250f-dec9-467b-cf25-d8b822a91eb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92.47\n",
            "[[ 1  0  2 ...  2  2  7]\n",
            " [ 4  2 79 ...  4  0  2]\n",
            " [ 4 90  0 ...  1  0  1]\n",
            " ...\n",
            " [ 3  4  0 ...  5 27  4]\n",
            " [12  2  0 ... 28  4  5]\n",
            " [14  0  2 ...  1  1  6]]\n"
          ]
        }
      ],
      "source": [
        "def bagging_accuracy(result):\n",
        "    count = 0\n",
        "    size = result.shape[0]\n",
        "    for idx in range(size):\n",
        "        ls = result[idx][-1]\n",
        "        class_freq = result[idx][:-1]\n",
        "        label = np.argmax(class_freq)\n",
        "        if ls == label:\n",
        "            count += 1\n",
        "    return (count/size*100)\n",
        "\n",
        "print(bagging_accuracy(aggregate_result))\n",
        "print(aggregate_result)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Final_code.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}